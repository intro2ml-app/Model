# Model
A Refined RAG (Retrieval-Augmented Generation) Architecture Model

## Setup

To get started, install the required dependencies by running:

```bash
pip install -r requirements.txt
```

## Running the API

Once the setup is complete, you can start the FastAPI server by executing:

```bash
uvicorn chatbot_api:app --reload
```

This command will launch the API server, accessible at `http://127.0.0.1:8000`.

### API Endpoints

#### **POST /query**
This endpoint handles user queries and returns a response generated by the chatbot.

**Request:**
- URL: `http://127.0.0.1:8000/query`
- Method: `POST`
- Body (JSON):

```json
{
  "query": "What is the capital of Vietnam?",
  "model": "your-model-name",
  "temperature": 0.7,
  "top_p": 0.9,
  "max_tokens": 100,
  "stream": false
}
```

**Parameters:**
- `query` (required): User's input, either a string or a list of messages with roles and content.
- `model` (required): The model name to use for generating responses.
- `temperature` (optional): Sampling temperature, defaults to `None`.
- `top_p` (optional): Nucleus sampling probability, defaults to `None`.
- `max_tokens` (optional): Maximum number of tokens in the response, defaults to `None`.
- `stream` (optional): Boolean to enable/disable response streaming, defaults to `false`.

**Response:**
- If `stream` is `false`, the response will be returned as a complete JSON object:

```json
{
  "response": "The capital of Vietnam is Hanoi."
}
```

- If `stream` is `true`, the response will be returned as a stream of data chunks, allowing real-time updates.

#### **POST /name**
This endpoint helps generate a name for a conversation based on the user's query. The response is generated in the same language as the user's input.

**Request:**
- URL: `http://127.0.0.1:8000/name`
- Method: `POST`
- Body (JSON):

```json
{
  "query": "Suggest a name for this conversation.",
}
```
**Parameters:**
- `query` (required): User's first input in the conversation.

**Response:**
```json
{
  "response": "Conversation naming."
}
```

**Error Handling:**
- If invalid parameters are provided, the API will return a `400 Bad Request` error with details.
- For internal errors, a `500 Internal Server Error` is returned.

## Stopping the Server

To stop the API server, press `Ctrl+C` in the terminal where it is running.

## Troubleshooting

### Missing Environment Variables
Ensure a `.env` file exists and contains all necessary environment variables, such as API keys and configuration details.

### Port Conflicts
If port `8000` is already in use, specify a different port using the `--port` option:

```bash
uvicorn chatbot_api:app --reload --port 8080
```

### Common Errors
- **Invalid Parameters**: Ensure the query and parameters conform to the expected format.
- **Connection Issues**: Verify your internet connection and API key settings.

## Features
- **Supports Multiple Input Formats**: Accepts user queries as either a string or a list of structured messages.
- **Configurable Parameters**: Customize model behavior with options like `temperature`, `top_p`, and `max_tokens`.
- **Streaming Support**: Optionally enable real-time streaming of responses for a dynamic user experience.

---

### Example Usage

Start the server:

```bash
uvicorn chatbot_api:app --reload
```

Send a query using `curl`:

```bash
curl -X POST "http://127.0.0.1:8000/query" \
-H "Content-Type: application/json" \
-d '{
  "query": "Explain the concept of retrieval-augmented generation.",
  "model": "your-model-name",
  "temperature": 0.7
}'
```

Expected Response:

```json
{
  "response": "Retrieval-Augmented Generation (RAG) combines information retrieval techniques with generative models to provide accurate and contextually relevant answers."
}
